# -*- coding: utf-8 -*-
"""AI Queue Prediction

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1E2MYbqEgu3MVByWiSimEmbUtJvFH-9uy

Installation of the libraries
"""

!pip install scikit-learn pandas numpy requests matplotlib seaborn joblib -q

print("Library installed!")

"""Function of prediction"""

import numpy as np
import pandas as pd
import requests
import json
from datetime import datetime, timedelta
import time
import logging
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error
import joblib
import matplotlib.pyplot as plt
import seaborn as sns
from collections import deque
import warnings
warnings.filterwarnings('ignore')

"""Function for scraping database data"""

class QueueTimePredictor:
    def __init__(self):
        # Configurazione Firebase
        self.firebase_url = "https://esp32device-2fe39-default-rtdb.asia-southeast1.firebasedatabase.app"

        # Modelli ML
        self.rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
        self.lr_model = LinearRegression()
        self.scaler = StandardScaler()

        # Buffer dati storici
        self.sensor_history = deque(maxlen=1000)
        self.people_history = deque(maxlen=500)
        self.queue_events = deque(maxlen=200)

        # Parametri predizione
        self.service_time_avg = 120  # Tempo medio servizio (secondi)
        self.service_time_std = 30   # Deviazione standard
        self.model_trained = False

        print("🎯 Queue Time Predictor initialized")

    def fetch_sensor_data(self):
        """Recover all data sensors of ESP32-WROOM from Firebase"""
        try:
            url = f"{self.firebase_url}/esp32-wroom/data.json"
            response = requests.get(url, timeout=10)

            if response.status_code == 200:
                data = response.json()
                if data:
                    print(f"Recovered {len(data)} record of sensors")
                    return data
            return None

        except Exception as e:
            print(f"❌ Errore fetch sensors: {e}")
            return None

    def fetch_people_detections(self):
        """Recover all the detection from people_detected"""
        try:
            url = f"{self.firebase_url}/people-detected.json"
            response = requests.get(url, timeout=10)

            if response.status_code == 200:
                data = response.json()
                if data:
                    print(f" Recovered {len(data)} detection of people")
                    return data
            return None

        except Exception as e:
            print(f"Errore on fetch people: {e}")
            return None

    def process_sensor_data(self, sensor_data):
        """Process sensor data per features ML"""
        processed_data = []

        for timestamp, data in sensor_data.items():
            try:
                ts = int(timestamp) if timestamp.isdigit() else int(data.get('timestamp', 0))
                dt = datetime.fromtimestamp(ts / 1000)

                features = {
                    'timestamp': ts,
                    'datetime': dt,
                    'hour': dt.hour,
                    'day_of_week': dt.weekday(),
                    'pressure': data.get('pressure', 0),
                    'distance': data.get('distance', -1),
                    'is_occupied': 1 if data.get('status') == 'occupied' else 0,
                    'wifi_rssi': data.get('wifi_rssi', 0)
                }

                processed_data.append(features)

            except Exception as e:
                continue

        return pd.DataFrame(processed_data).sort_values('timestamp').reset_index(drop=True)

    def process_people_data(self, people_data):
        """Process detection of people per features ML"""
        processed_data = []

        for key, data in people_data.items():
            try:
                timestamp_str = data.get('timestamp', '')
                if 'T' in timestamp_str:
                    dt = datetime.fromisoformat(timestamp_str.replace('Z', '+00:00'))
                    ts = int(dt.timestamp() * 1000)
                else:
                    ts = int(data.get('timestamp', 0))
                    dt = datetime.fromtimestamp(ts / 1000)

                people_count = data.get('count', 0)

                features = {
                    'timestamp': ts,
                    'datetime': dt,
                    'people_count': people_count,
                    'detection_status': 1 if people_count > 0 else 0,
                    'confidence': data.get('confidence', 0.5)
                }

                processed_data.append(features)

            except Exception as e:
                continue

        return pd.DataFrame(processed_data).sort_values('timestamp').reset_index(drop=True)

    def create_queue_events(self, sensor_df, people_df):
        """Create events from data"""
        if sensor_df.empty or people_df.empty:
            return pd.DataFrame()

        # Resample a finestre di 60 secondi
        sensor_df.set_index('datetime', inplace=True)
        people_df.set_index('datetime', inplace=True)

        sensor_agg = sensor_df.resample('60S').agg({
            'pressure': 'mean',
            'distance': 'mean',
            'is_occupied': 'max',
            'hour': 'first',
            'day_of_week': 'first'
        }).dropna()

        people_agg = people_df.resample('60S').agg({
            'people_count': 'max',
            'detection_status': 'max',
            'confidence': 'mean'
        }).dropna()

        # Combina
        combined = pd.merge(sensor_agg, people_agg,
                          left_index=True, right_index=True, how='inner')

        # Features avanzate
        combined['total_occupancy'] = combined['is_occupied'] + combined['detection_status']
        combined['queue_intensity'] = combined['people_count'] * combined['detection_status']
        combined['busy_score'] = (combined['pressure'] / 1000) + combined['people_count']
        combined['distance_factor'] = np.where(combined['distance'] > 0,
                                             1 / (combined['distance'] / 100), 0)

        # Stima tempo attesa
        combined['estimated_wait_time'] = self.calculate_empirical_wait_time(combined)

        return combined.reset_index()

    def calculate_empirical_wait_time(self, data):
        """Calcola tempo attesa empirico"""
        wait_times = []

        for _, row in data.iterrows():
            base_time = 0

            # Fattore persone
            if row['people_count'] > 0:
                base_time += row['people_count'] * self.service_time_avg

            # Fattore pressione
            if row['is_occupied']:
                base_time += self.service_time_avg * 0.5

            # Fattore orario
            hour = row['hour']
            if hour in [8, 9, 12, 13, 17, 18, 19]:
                base_time *= 1.5
            elif hour in [10, 11, 14, 15, 16]:
                base_time *= 1.0
            else:
                base_time *= 0.7

            # Fattore giorno
            if row['day_of_week'] < 5:
                base_time *= 1.2
            else:
                base_time *= 0.9

            base_time = max(0, base_time)
            noise = np.random.normal(0, self.service_time_std)
            final_time = max(0, base_time + noise)

            wait_times.append(final_time)

        return wait_times

    def train_model(self, queue_data):
        """Training ML models"""
        if queue_data.empty or len(queue_data) < 10:
            print("Insufficient data for training")
            return False

        try:
            feature_columns = [
                'hour', 'day_of_week', 'pressure', 'distance',
                'is_occupied', 'people_count', 'detection_status',
                'total_occupancy', 'queue_intensity', 'busy_score', 'distance_factor'
            ]

            X = queue_data[feature_columns].fillna(0)
            y = queue_data['estimated_wait_time']

            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=0.2, random_state=42
            )

            X_train_scaled = self.scaler.fit_transform(X_train)
            X_test_scaled = self.scaler.transform(X_test)

            # Training
            self.rf_model.fit(X_train, y_train)
            rf_pred = self.rf_model.predict(X_test)
            rf_mae = mean_absolute_error(y_test, rf_pred)

            self.lr_model.fit(X_train_scaled, y_train)
            lr_pred = self.lr_model.predict(X_test_scaled)
            lr_mae = mean_absolute_error(y_test, lr_pred)

            print(f"✅ Abstract models:")
            print(f"   Random Forest MAE: {rf_mae:.1f} seconds")
            print(f"   Linear Regression MAE: {lr_mae:.1f} seconds")

            self.model_trained = True
            return True

        except Exception as e:
            print(f"❌ Errore on training: {e}")
            return False

    def predict_wait_time(self, current_features):
        """Predict queue waiting time"""
        if not self.model_trained:
            return self.estimate_wait_time_simple(current_features)

        try:
            feature_columns = [
                'hour', 'day_of_week', 'pressure', 'distance',
                'is_occupied', 'people_count', 'detection_status',
                'total_occupancy', 'queue_intensity', 'busy_score', 'distance_factor'
            ]

            X = np.array([[current_features.get(col, 0) for col in feature_columns]])

            rf_pred = self.rf_model.predict(X)[0]
            X_scaled = self.scaler.transform(X)
            lr_pred = self.lr_model.predict(X_scaled)[0]

            final_prediction = (rf_pred * 0.7) + (lr_pred * 0.3)
            final_prediction = max(0, min(final_prediction, 1800))

            return final_prediction

        except Exception as e:
            print(f"Error in prediction: {e}")
            return self.estimate_wait_time_simple(current_features)

    def estimate_wait_time_simple(self, features):
        """ML extimation"""
        base_time = 0

        people = features.get('people_count', 0)
        if people > 0:
            base_time += people * self.service_time_avg

        if features.get('is_occupied', False):
            base_time += self.service_time_avg * 0.5

        hour = features.get('hour', 12)
        if hour in [8, 9, 12, 13, 17, 18, 19]:
            base_time *= 1.5

        return max(0, min(base_time, 1800))

    def format_wait_time(self, seconds):
        """Setting time display"""
        if seconds < 60:
            return f"{int(seconds)} seconds"
        elif seconds < 3600:
            minutes = int(seconds / 60)
            return f"{minutes} minutes"
        else:
            hours = int(seconds / 3600)
            minutes = int((seconds % 3600) / 60)
            return f"{hours}h {minutes}m"

    def send_prediction_to_firebase(self, prediction_data):

        try:
            url = f"{self.firebase_url}/queue-predictions/{int(time.time() * 1000)}.json"
            response = requests.put(url, json=prediction_data, timeout=10)

            if response.status_code in [200, 201]:
                print("✅ Predinction sended to Firebase")

                current_url = f"{self.firebase_url}/queue-predictions/current.json"
                requests.put(current_url, json=prediction_data, timeout=10)
                return True
            else:
                print(f"Errore on sending: {response.status_code}")
                return False

        except Exception as e:
            print(f"Error Firebase: {e}")
            return False

print("✅ Class QueueTimePredictor defined!")

"""TESTING"""

predictor = QueueTimePredictor()

# Test connection to Firebase
print(" Test connection to Firebase...")
sensor_test = predictor.fetch_sensor_data()
people_test = predictor.fetch_people_detections()

if sensor_test:
    print(f"✅ Sensors: {len(sensor_test)} record founded")
else:
    print("⚠️ Nessun dato sensori trovato")

if people_test:
    print(f"✅ People detection: {len(people_test)} record founded")
else:
    print("No data of people queue found")

def train_prediction_model():
    """Executin the training"""
    print("Turning on training model...")

    # Fetch historical data
    sensor_data = predictor.fetch_sensor_data()
    people_data = predictor.fetch_people_detections()

    if sensor_data and people_data:
        # Processing data
        sensor_df = predictor.process_sensor_data(sensor_data)
        people_df = predictor.process_people_data(people_data)

        print(f"Processed {len(sensor_df)} record of sensor")
        print(f"Processed {len(people_df)} record of people")

        # Crea dataset training
        queue_data = predictor.create_queue_events(sensor_df, people_df)

        if not queue_data.empty:
            print(f"Queue dataset: {len(queue_data)} events")

            # Training
            success = predictor.train_model(queue_data)
            if success:
                print("🎉 Training completato con successo!")
            else:
                print("Training failed")
        else:
            print("No queue event generated")
    else:
        print("Impossible using data for training")

# Executing training
train_prediction_model()

def make_single_prediction():
    """Execute a single prediction"""
    print("Executing single prediction...")

    # Fetch current data
    sensor_data = predictor.fetch_sensor_data()
    people_data = predictor.fetch_people_detections()

    if sensor_data and people_data:
        # Processa
        sensor_df = predictor.process_sensor_data(sensor_data)
        people_df = predictor.process_people_data(people_data)

        # Create events
        queue_data = predictor.create_queue_events(sensor_df, people_df)

        if not queue_data.empty:
            # Last simulation
            latest_data = queue_data.iloc[-1]
            current_features = latest_data.to_dict()

            # Prediction
            predicted_wait = predictor.predict_wait_time(current_features)

            # Results
            print(f"\nPrediction results:")
            print(f"Waiting time estimated: {predictor.format_wait_time(predicted_wait)}")
            print(f"People found: {int(current_features.get('people_count', 0))}")
            print(f"Queue length: {current_features.get('distance', -1)} cm")
            print(f"Occupied: {'Yes' if current_features.get('is_occupied', False) else 'No'}")
            print(f"Queue intensity: {current_features.get('queue_intensity', 0):.2f}")

            # Preparing data on firebase
            prediction_data = {
                'timestamp': datetime.now().isoformat(),
                'predicted_wait_seconds': predicted_wait,
                'predicted_wait_formatted': predictor.format_wait_time(predicted_wait),
                'current_people': int(current_features.get('people_count', 0)),
                'current_distance': current_features.get('distance', -1),
                'sensor_occupied': bool(current_features.get('is_occupied', False)),
                'detection_active': bool(current_features.get('detection_status', False)),
                'confidence_level': 'high' if predictor.model_trained else 'medium',
                'queue_intensity': current_features.get('queue_intensity', 0),
                'busy_score': current_features.get('busy_score', 0)
            }

            # Sending to firebase
            predictor.send_prediction_to_firebase(prediction_data)

            return prediction_data
        else:
            print("No data for prediction")
            return None
    else:
        print("Impossible recovering data")
        return None

# Executing the single prediction
result = make_single_prediction()

def run_continuous_prediction(duration_minutes=30):
    """
    Do continuous predictions for a given duration in minutes.
    ATTENTION: This cell blocks the execution of the other celss!
    """
    print(f"Starting continuous prediction for {duration_minutes} minutes...")
    print("To stop the cell: Runtime → Interrupt execution")

    start_time = time.time()
    end_time = start_time + (duration_minutes * 60)
    cycle = 0

    try:
        while time.time() < end_time:
            cycle += 1
            print(f"\n--- Cycle {cycle} ---")

            # Predizione
            make_single_prediction()

            # Pause of 30 seconds
            print("⏳ Pause of 30 seconds...")
            time.sleep(30)

    except KeyboardInterrupt:
        print("Manual Interruption")

    print("Continuous prediction terminated")

# Comment or decomment to activate the continuous prediction
run_continuous_prediction(30)  # 30 minutes of prediction

print("\n🎉 Setup Google Colab completed!")